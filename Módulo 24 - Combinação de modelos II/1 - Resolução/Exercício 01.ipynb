{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d9d7e5-dd35-4222-9f5b-2ad51ce3291f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Combinação de modelos II | Exercício 1**\n",
    "\n",
    "**Aluno:** Guilherme Rhein\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc89696-b7e1-4be3-b493-c6b863fa337f",
   "metadata": {},
   "source": [
    "# Tarefa 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05220745-5553-46bf-9721-3e16cccd3285",
   "metadata": {},
   "source": [
    "**1.** Cite 5 diferenças entre o Random Forest e o AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db295d28-729f-4b9f-943b-bc31ccb47ce2",
   "metadata": {},
   "source": [
    "| Random Forest | AdaBoost|\n",
    "| --- | --- |\n",
    "Trabalha com uma floresta de árvores completas. | Utiliza uma **Stump** que é definida como um classificador fraco por apresentar uma estrutura de 2 folhas e 1 de profundidade. |\n",
    "As árvores de decisão em uma Random Forest são construídas de forma independente e paralela. Cada árvore é treinada em uma amostra aleatória do conjunto de dados, usando um subconjunto aleatório de características. | AdaBoost são construídos sequencialmente, um de cada vez. Cada modelo subsequente se concentra nas instâncias mal classificadas pelos modelos anteriores, ajustando os pesos para corrigir as classificações erradas. |\n",
    "Atribui pesos iguais a todas as instâncias de treinamento. Cada árvore de decisão na floresta é treinada de maneira independente e não considera o desempenho das árvores anteriores. | Atribui pesos diferentes às instâncias de treinamento, dando mais ênfase às instâncias mal classificadas anteriormente. Isso permite que o modelo se concentre mais nas instâncias difíceis de classificar. |\n",
    "Utiliza **feature selection** definindo uma quantidade de variáveis aleatórias para serem utilizadas em cada árvore. | Utiliza somente uma variável para cada **Stump**. |\n",
    "Utiliza votação simples como previsão. | Utiliza votação ponderada de acordo com a performance de cada **Stump**. \n",
    "| Random Forest é mais robusto em relação a outliers, pois a influência de um único exemplo é diluída entre várias árvores de decisão. | É mais sensível a outliers, pois atribui pesos mais altos às instâncias mal classificadas. Se um exemplo é difícil de classificar e é considerado um outlier, o AdaBoost pode ficar excessivamente focado nesse exemplo, comprometendo o desempenho geral. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89239d72-96bc-47e4-b991-b1e709be253c",
   "metadata": {},
   "source": [
    "**2.** Acesse o link [- Adaboost](https://scikit-learn.org/stable/modules/ensemble.html), leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo do AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a1819c-32c7-4923-a726-316782116e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.ensemble        import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0424eee9-4d7c-4b5d-a49e-db5a1aba574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y   = load_iris(return_X_y=True)\n",
    "\n",
    "clf    = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49e8a9-17c5-4a26-8acc-c73363ef763e",
   "metadata": {},
   "source": [
    "**3.** Cite 5 Hiperparâmetros importantes no AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304fe17-f940-4cd8-8259-e9c91e28c7bb",
   "metadata": {},
   "source": [
    "> **1. estimator**: Especifica o estimador que será utilizado como base para o AdaBoost, podendo ser utilizado qualquer modelo de aprendizado de máquina, como árvores de decisão, regressão linear. O estimador padrão é `DecisionTreeClassifier(max_depth=1)`.\n",
    ">> ```estimator: object, default=None``` \n",
    ">\n",
    "> **2. n_estimators**: Número de iterações para o processo de aprendizagem. Representa o número de estimadores fracos (ou modelos fracos, Stumps) que serão combinados para formar o modelo final. Um valor maior pode levar a um desempenho melhor, mas também pode aumentar o tempo de treinamento.(Quantidade de **Stumps**.)\n",
    ">> ```n_estimators: int, default=50```\n",
    "\n",
    "> **3. learning_rate**: Determina o **Peso** aplicado a cada classificador nas iterações. Controla a contribuição de cada modelo fraco para o modelo final. Um valor menor geralmente resulta em um treinamento mais lento, mas pode melhorar a generalização. É um fator que multiplica as contribuições dos modelos fracos.\n",
    ">> ```learning_rate: float, default=1.0```\n",
    ">\n",
    "> **4. algorithm**: Define o algoritmo utilizado para atualizar os pesos dos exemplos durante o treinamento. Pode ser \"SAMME\" (Stagewise Additive Modeling using a Multi-class Exponential loss function) ou \"SAMME.R\" (SAMME com reponderação), onde \"SAMME.R\" é recomendado para melhor desempenho.\n",
    ">>```algorithm{‘SAMME’, ‘SAMME.R’}, default=’SAMME.R’```\n",
    ">\n",
    "> **5. base_estimator_params**: É um dicionário opcional que permite especificar parâmetros para o estimador fraco. Esses parâmetros serão passados para o construtor do estimador fraco em cada iteração.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f22e83d-a610-42d5-b995-a1d238f5c1d5",
   "metadata": {},
   "source": [
    "**4.** Utilize o GridSearch para encontrar os melhores hiperparâmetros para o conjunto de dados do exemplo (load_iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f905aa-f7cb-460f-8522-e87a602e421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.2 s\n",
      "Wall time: 29.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>92</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>122</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>137</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>152</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>167</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>182</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>197</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>212</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>227</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>242</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>257</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>272</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>287</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  mean_score\n",
       "0              2    0.946667\n",
       "1             17    0.953333\n",
       "2             32    0.946667\n",
       "3             47    0.940000\n",
       "4             62    0.946667\n",
       "5             77    0.953333\n",
       "6             92    0.946667\n",
       "7            107    0.940000\n",
       "8            122    0.946667\n",
       "9            137    0.953333\n",
       "10           152    0.946667\n",
       "11           167    0.940000\n",
       "12           182    0.940000\n",
       "13           197    0.946667\n",
       "14           212    0.946667\n",
       "15           227    0.940000\n",
       "16           242    0.940000\n",
       "17           257    0.946667\n",
       "18           272    0.946667\n",
       "19           287    0.940000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimators = list(range(2, 300, 15))\n",
    "\n",
    "n_estimators = []\n",
    "mean_scores  = []\n",
    "\n",
    "for n in estimators:\n",
    "    clf = AdaBoostClassifier(n_estimators=n)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    n_estimators.append(n)\n",
    "    mean_scores.append(scores.mean())\n",
    "\n",
    "df = pd.DataFrame(list(zip(n_estimators, mean_scores)))\n",
    "df = df.rename(columns={0:'n_estimators', 1:'mean_score'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5570d30-877b-48b6-8671-b9f1dd2a0268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
