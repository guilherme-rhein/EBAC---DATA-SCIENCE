{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01fe748-314a-4fa9-bbc8-b58cd625898d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Combinação de modelos II | Exercício 2**\n",
    "\n",
    "**Aluno:** Guilherme Rhein\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87421f-2533-4f0f-9df1-61d76430e0bc",
   "metadata": {},
   "source": [
    "# Tarefa 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8c515-70bd-4e3d-a35e-267fc6101275",
   "metadata": {},
   "source": [
    "**1.** Cite 5 diferenças entre o AdaBoost e o GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b6575-ec87-489c-81f1-b49a29cbba70",
   "metadata": {},
   "source": [
    "| AdaBoost | GBM |\n",
    "| -------- | --- |\n",
    "| Utiliza árvores simples, chamados de **Stumps**. | Utiliza árvores completas e complexas. |\n",
    "| As **Stumps** são simples com 2 folhas e 1 de profundidade. | As árvores complexas exigem tratamento utilizando parâmetros específicos. |\n",
    "| O primeiro passo do modelo é a determinação de um peso para suas linhas e assim fazer a seleção da melhor **Stump** com o melhor desempenho. | O primeiro passo do modelo é o cálculo da média do Y. |\n",
    "| Cada linha tem um peso diferente para a agregação de um novo conjunto de dados, que força as linhas com maior erro a se repetirem mais vezes, melhorando o treinamento do modelo. | As árvores são calculadas através de um multiplicador em comum chamado **ETA**. |\n",
    "| A predição final é definida por votação ponderada das respostas de acordo com a performance de cada **Stump**. | A predição final é definida através do ajuste do modelo através do cálculo de resíduos. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6d6ef-fc2c-4a3b-af12-84f47a045206",
   "metadata": {},
   "source": [
    "**2.** Acesse o link [– GBM](https://scikit-learn.org/stable/modules/ensemble.html), leia a explicação e crie um jupyter notebook contendo o exemplo de classificação e de regressão do GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13c7a6-4b35-4549-a59b-020f1c7f8d97",
   "metadata": {},
   "source": [
    "## <br> **GBM - Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c18906a-757b-4c3b-8c96-d810bcafbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41a352d-e340-44bd-b6bf-431f9ac42aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_hastie_10_2(random_state=0)\n",
    "\n",
    "X_train, X_test = X[:2000], X[2000:]\n",
    "y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "                                 max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2a4b4-ae92-4479-b1fc-1288c22efb35",
   "metadata": {},
   "source": [
    "## <br> **GBM - Regressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39199baf-62e1-493b-a692-0fb21529054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics  import mean_squared_error\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a068a940-b305-4c6a-bccb-cef99e59d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.009154859960321"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_friedman1(n_samples=1200, random_state=0, noise=1.0)\n",
    "X_train, X_test = X[:200], X[200:]\n",
    "y_train, y_test = y[:200], y[200:]\n",
    "\n",
    "est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, \n",
    "                                max_depth=1, random_state=0, \n",
    "                                loss='squared_error').fit(X_train, y_train)\n",
    "mean_squared_error(y_test, est.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875633aa-d96e-460b-8487-a6743ef61926",
   "metadata": {},
   "source": [
    "**3.** Cite 5 hiperparâmetros importantes no GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86622a0-b73c-4c06-84dd-76f20ddf2fe9",
   "metadata": {},
   "source": [
    "> **1. n_estimators**: Número de árvores (estimadores) a serem ajustados. Geralmente, um valor maior leva a um modelo mais robusto, mas também aumenta o tempo de treinamento.\n",
    ">\n",
    "> **2. learning_rate**: Taxa de aprendizado entre 0.0 e 1.0, que controla a contribuição de cada estimador. Valores menores geralmente requerem mais estimadores para atingir a mesma performance.\n",
    ">\n",
    "> **3. max_depth**: Profundidade máxima dos estimadores individuais. Ajustar este parâmetro pode ajudar a evitar overfitting.\n",
    ">\n",
    "> **4. max_features**: O número de variáveis a serem consideradas ao procurar a melhor divisão. Pode ser um valor inteiro, uma fração (0.5 para considerar metade das features), 'sqrt' (raiz quadrada do número total de features), 'log2' (logaritmo base 2 do número total de features) ou None para considerar todas as features.\n",
    ">\n",
    "> **5. warm_start**: Permite adicionar mais estimadores a um modelo já existente. Pode ser útil quando é necessário ajustar o modelo com mais árvores sem perder o progresso anterior ou atualizar suas necessidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d6267-19e7-47d2-b795-a68bcd361515",
   "metadata": {},
   "source": [
    "**4.** Utilize o GridSearch para encontrar os melhores hiperparâmetros para o conjunto de dados do exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28d502b-a871-4962-9fb7-870f12a9ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 39s\n",
      "Wall time: 11min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.04, 0.06, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [2, 5, 7, 11],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100, 500, 1000]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.04, 0.06, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [2, 5, 7, 11],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100, 500, 1000]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'learning_rate': [0.04, 0.06, 0.1, 0.3],\n",
       "                         'max_depth': [2, 5, 7, 11],\n",
       "                         'n_estimators': [10, 100, 500, 1000]},\n",
       "             scoring='r2', verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbr = GradientBoostingClassifier()\n",
    "\n",
    "parametros = {\n",
    "    'n_estimators': [10, 100, 500, 1000],\n",
    "    'max_depth': [2, 5, 7, 11],\n",
    "    'learning_rate': [0.04, 0.06, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=gbr,\n",
    "                    param_grid=parametros,\n",
    "                    scoring='r2',\n",
    "                    verbose=False,\n",
    "                    cv=2)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "365c3893-bccd-4ef6-8b30-f05f1a1580bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3626d38-2715-4033-9fcb-6f477d8e8272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5.554647</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.587866</td>\n",
       "      <td>0.635854</td>\n",
       "      <td>0.611860</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.778261</td>\n",
       "      <td>0.032149</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.599870</td>\n",
       "      <td>0.623850</td>\n",
       "      <td>0.611860</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.547439</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.599870</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.595854</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.972728</td>\n",
       "      <td>0.122756</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.06, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>0.551855</td>\n",
       "      <td>0.575830</td>\n",
       "      <td>0.563843</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.749467</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.547854</td>\n",
       "      <td>0.555822</td>\n",
       "      <td>0.551838</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "51       5.554647      0.009656         0.007814        0.007814   \n",
       "50       2.778261      0.032149         0.007812        0.007812   \n",
       "35       5.547439      0.030810         0.013888        0.013888   \n",
       "19       5.972728      0.122756         0.012195        0.000193   \n",
       "34       2.749467      0.000216         0.007813        0.007813   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "51                 0.3               2               1000   \n",
       "50                 0.3               2                500   \n",
       "35                 0.1               2               1000   \n",
       "19                0.06               2               1000   \n",
       "34                 0.1               2                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "51  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...           0.587866   \n",
       "50  {'learning_rate': 0.3, 'max_depth': 2, 'n_esti...           0.599870   \n",
       "35  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.599870   \n",
       "19  {'learning_rate': 0.06, 'max_depth': 2, 'n_est...           0.551855   \n",
       "34  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.547854   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "51           0.635854         0.611860        0.023994                1  \n",
       "50           0.623850         0.611860        0.011990                2  \n",
       "35           0.591837         0.595854        0.004017                3  \n",
       "19           0.575830         0.563843        0.011988                4  \n",
       "34           0.555822         0.551838        0.003984                5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = grid.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd77068-5da9-48bf-b7b7-c88ff2978b5e",
   "metadata": {},
   "source": [
    "**5.** Acessando o artigo do Jerome Friedman ([Stochastic](https://jerryfriedman.su.domains/ftp/stobst.pdf)) e pensando no nome dado ao **Stochastic GBM**, qual é a maior diferença entre os dois algoritmos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3fde36-2bb7-46f9-ba26-55627bea0d8a",
   "metadata": {},
   "source": [
    "> A maior diferença entre o Gradient Boosting Machine (GBM) padrão e o artigo do Jerome Friedman está na introdução de aleatoriedade no processo de treinamento. Enquanto o GBM utiliza o conjunto de treinamento completo para ajustar cada árvore de decisão, o artigo de Jerome Friedman introduz estocasticidade amostrando aleatoriamente subconjuntos do conjunto de treinamento para ajustar cada árvore. O Stochastic GBM é uma combinação dos métodos de Gradient Boosting e Bootstrap Aggregating, sendo considerado um híbrido das técnicas Bagging e Boosting. Essa aleatoriedade na amostragem do conjunto de dados em cada iteração de treino melhora significativamente a precisão do Gradient Boosting e torna o modelo mais robusto em comparação com o GBM tradicional. Isso ocorre porque a aleatoriedade ajuda a evitar o overfitting e promove uma melhor generalização do modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
